[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "The materials provided in this repository are FREE to use.\nThis work is licensed under a Creative Commons Attribution 4.0 International License. Reuse is encouraged with acknowledgement."
  },
  {
    "objectID": "Syllabus.html",
    "href": "Syllabus.html",
    "title": "Training Syllabus",
    "section": "",
    "text": "Topics to be addressed during the workshop\n\n\n\nTraining Objectives\nLearning objectives. By the end of the workshop, the participants will be able to\n\n\nTargeted competencies and Knowledge, Skills and Attitudes\n\n\nTraining Methods and Instructional Strategies\n\n\nDuration of training\n\n\nSchedule of sessions\n\n\nAssessment and Evaluation\n\n\nResources\n\n\nRecommended background knowledge"
  },
  {
    "objectID": "agenda.html",
    "href": "agenda.html",
    "title": "Agenda",
    "section": "",
    "text": "Prerequisites for following this course.\n\nYou are expected to be comfortable with bash and also with a text editor such as vi or nano. If you are not, try to practice a few commands before you attempt to follow the steps below.\nPlease make sure you have received from your course instructor the Public IPv4 of your Amazon EC2 instance, the name of the machine you are going to work on and also a public key to access the machine via ssh."
  },
  {
    "objectID": "data-flo/data-flo.html",
    "href": "data-flo/data-flo.html",
    "title": "Data-flo tutorial",
    "section": "",
    "text": "Data-flo (https://data-flo.io/) is a system for customised integration and manipulation of diverse data via a simple drag and drop interface.\nFor Data-flo documentation, go to https://docs.data-flo.io/introduction/readme\nData-flo can easily combine epidemiological data, genomic data, laboratory data, and various metadata from disparate sources (i.e., different data systems) and formats.\nData-flo provides a visual method to design a reusable pipeline to integrate, clean, and manipulate data in a multitude of ways, eliminating the need for continuous manual intervention (e.g., coding, formatting, spreadsheet formulas, manual copy-pasting).\nData-flo pipelines are combinations of ready-to-use data adaptors that can be tailored, modularised and shared for reuse and reproducibility. Once a Data-flo pipeline has been created, it can be run anytime, by anyone with access, to enable push-button data extraction and transformation. This saves significant time by removing the bulk of the manual repetitive workflows that require multiple sequential or tedious steps, enabling practitioners to focus on analysis and interpretation.\n\n\n“Steps” in Data-flo are called ADAPTORS. There are three main types of adaptors, which serve different functions.\n\nImporting data\nManipulating & transforming data\nExporting data\n\n\n\n\nData-flo editing view. Examples of Data-flo adaptors.\n\n\n\n\n\nData-flo editing view. This is an example of a Data-flo that imports data from Google spreadsheets, through “Google spreadsheet” adaptors.\n\n\n\n\n\nData-flo editing view. This is an example of a Data-flo where two datatables are merged using a “Join datatables” adaptor.\n\n\n\n\n\nData-flo editing view. Using various adaptors, columns in a datatable can be removed or renamed, specific strings or blank values can be replaced, dates can be reformatted, distinct lists can be generated.\n\n\n\n\n\nData-flo editing view. In this example, a Data-flo pushes updated data to a Microreact project and supplies the URL for that project using the “Update Microreact project” adaptor.\n\n\n\n\n\n\n\n\nHow to run a Data-flo, Step 1: Go to Data-flo transformations: data-flo.io/transformations/dataflows\n\n\n\n\n\nHow to run a Data-flo, Step 2: Select your favourite Data-flo. The Data-flo shown in this example is “Lab to bioinformatics”\n\n\n\n\n\nHow to run a Data-flo, Step 3: Click on the RUN tab to get to the RUN page.\n\n\n\n\n\nHow to run a Data-flo, Step 4: Hit the RUN button.\n\n\n\n\n\nHow to run a Data-flo, Step 5: Check out the output. In this example, the output is a Microreact link. You can choose to RUN AGAIN the Data-flo, and this will update your results (in case the input had been changed, of course).\n\n\n\n\n\nCreate a Data-flo from scratch, Step 1: Go to the + sign on the bottom right of your screen.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 2: Select “NEW DATAFLOW”.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 3: Select your preferred ACCESS CONTROL.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 4: Add adaptors to your Data-flo. On the left-hand side of Data-flo, you can find the list of available adaptors.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 5: Try to retrieve data from a spreadsheet. Click on “Spreadsheet file” on the list of adaptors. Hover over the “i” button next to “Spreadsheet file” to see basic information about this adaptor.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 6: Clicking on “Spreadsheet file” on the list of adaptors, will add an adaptor (which looks like a box), with the title “Spreadsheet file” on your canvas. When you click on *file on the left side of the adaptor, the view on the right hand side of your screen will change, and you will be able to see a list of options under “BINDING TYPE”, such as “Bind to a Dataflow input” and “Bind to another transformation”.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 7: From the list of “BINDING TYPEs”, Select “Bind to a Dataflow input” and press the “+” next to INPUT ARGUMENT.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 8: A box with “file” will appear on the canvas, linked to the “Spreadsheet file” adaptor.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 9: To run a Data-flo, press the little “bug icon” on top, on the right hand side of the Save button.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 10: Pressing the “bug icon” will trigger the Dataflow Debugger and you will be shown a “Choose file” button.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 11: Press the “Choose file” button and select a spreadsheet from your local computer. Click the “data” on the right hand side of the adaptor.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 12: Clicking on the “data” on the right hand side of the adaptor, will retrieve a view of the file selected. In this case, the Dataflow Debugger is showing the first 3 rows of a file containing epidemiological data.\n\n\n\n\n\n\n\n\nHow to share your Data-flo, Step 1: Press the downward facing arrow shown here on the top right corner. This will trigger the export of a .json file, which can be sent and shared.\n\n\n\n\n\nHow to share your Data-flo, Step 2: If you have received a .json Data-flo file, press the + sign at the bottom right of your screen\n\n\n\n\n\nHow to share your Data-flo, Step 3: Press the IMPORT button and then select your .json file containing the Data-flo."
  },
  {
    "objectID": "data-flo/data-flo.html#a-short-introduction",
    "href": "data-flo/data-flo.html#a-short-introduction",
    "title": "Data-flo tutorial",
    "section": "",
    "text": "Data-flo (https://data-flo.io/) is a system for customised integration and manipulation of diverse data via a simple drag and drop interface.\nFor Data-flo documentation, go to https://docs.data-flo.io/introduction/readme\nData-flo can easily combine epidemiological data, genomic data, laboratory data, and various metadata from disparate sources (i.e., different data systems) and formats.\nData-flo provides a visual method to design a reusable pipeline to integrate, clean, and manipulate data in a multitude of ways, eliminating the need for continuous manual intervention (e.g., coding, formatting, spreadsheet formulas, manual copy-pasting).\nData-flo pipelines are combinations of ready-to-use data adaptors that can be tailored, modularised and shared for reuse and reproducibility. Once a Data-flo pipeline has been created, it can be run anytime, by anyone with access, to enable push-button data extraction and transformation. This saves significant time by removing the bulk of the manual repetitive workflows that require multiple sequential or tedious steps, enabling practitioners to focus on analysis and interpretation.\n\n\n“Steps” in Data-flo are called ADAPTORS. There are three main types of adaptors, which serve different functions.\n\nImporting data\nManipulating & transforming data\nExporting data\n\n\n\n\nData-flo editing view. Examples of Data-flo adaptors.\n\n\n\n\n\nData-flo editing view. This is an example of a Data-flo that imports data from Google spreadsheets, through “Google spreadsheet” adaptors.\n\n\n\n\n\nData-flo editing view. This is an example of a Data-flo where two datatables are merged using a “Join datatables” adaptor.\n\n\n\n\n\nData-flo editing view. Using various adaptors, columns in a datatable can be removed or renamed, specific strings or blank values can be replaced, dates can be reformatted, distinct lists can be generated.\n\n\n\n\n\nData-flo editing view. In this example, a Data-flo pushes updated data to a Microreact project and supplies the URL for that project using the “Update Microreact project” adaptor.\n\n\n\n\n\n\n\n\nHow to run a Data-flo, Step 1: Go to Data-flo transformations: data-flo.io/transformations/dataflows\n\n\n\n\n\nHow to run a Data-flo, Step 2: Select your favourite Data-flo. The Data-flo shown in this example is “Lab to bioinformatics”\n\n\n\n\n\nHow to run a Data-flo, Step 3: Click on the RUN tab to get to the RUN page.\n\n\n\n\n\nHow to run a Data-flo, Step 4: Hit the RUN button.\n\n\n\n\n\nHow to run a Data-flo, Step 5: Check out the output. In this example, the output is a Microreact link. You can choose to RUN AGAIN the Data-flo, and this will update your results (in case the input had been changed, of course).\n\n\n\n\n\nCreate a Data-flo from scratch, Step 1: Go to the + sign on the bottom right of your screen.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 2: Select “NEW DATAFLOW”.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 3: Select your preferred ACCESS CONTROL.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 4: Add adaptors to your Data-flo. On the left-hand side of Data-flo, you can find the list of available adaptors.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 5: Try to retrieve data from a spreadsheet. Click on “Spreadsheet file” on the list of adaptors. Hover over the “i” button next to “Spreadsheet file” to see basic information about this adaptor.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 6: Clicking on “Spreadsheet file” on the list of adaptors, will add an adaptor (which looks like a box), with the title “Spreadsheet file” on your canvas. When you click on *file on the left side of the adaptor, the view on the right hand side of your screen will change, and you will be able to see a list of options under “BINDING TYPE”, such as “Bind to a Dataflow input” and “Bind to another transformation”.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 7: From the list of “BINDING TYPEs”, Select “Bind to a Dataflow input” and press the “+” next to INPUT ARGUMENT.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 8: A box with “file” will appear on the canvas, linked to the “Spreadsheet file” adaptor.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 9: To run a Data-flo, press the little “bug icon” on top, on the right hand side of the Save button.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 10: Pressing the “bug icon” will trigger the Dataflow Debugger and you will be shown a “Choose file” button.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 11: Press the “Choose file” button and select a spreadsheet from your local computer. Click the “data” on the right hand side of the adaptor.\n\n\n\n\n\nCreate a Data-flo from scratch, Step 12: Clicking on the “data” on the right hand side of the adaptor, will retrieve a view of the file selected. In this case, the Dataflow Debugger is showing the first 3 rows of a file containing epidemiological data.\n\n\n\n\n\n\n\n\nHow to share your Data-flo, Step 1: Press the downward facing arrow shown here on the top right corner. This will trigger the export of a .json file, which can be sent and shared.\n\n\n\n\n\nHow to share your Data-flo, Step 2: If you have received a .json Data-flo file, press the + sign at the bottom right of your screen\n\n\n\n\n\nHow to share your Data-flo, Step 3: Press the IMPORT button and then select your .json file containing the Data-flo."
  },
  {
    "objectID": "microreact/microreact.html",
    "href": "microreact/microreact.html",
    "title": "Microreact tutorial",
    "section": "",
    "text": "For Microreact documentation, go to https://docs.microreact.org/"
  },
  {
    "objectID": "microreact/microreact.html#task-1-create-an-editable-project.",
    "href": "microreact/microreact.html#task-1-create-an-editable-project.",
    "title": "Microreact tutorial",
    "section": "Task 1: Create an editable project.",
    "text": "Task 1: Create an editable project.\n\n\n\nTask 1: Create an editable project. Step 1: Notice the crossed out pen on right top corner of your screen. This indicates that you cannot edit the current Microreact project.\n\n\n\n\n\nTask 1: Create an editable project. Step 2: Click the crossed out “Pen” symbol in the top right of the screen. A window appears asking you to “SIGN IN TO EDIT”.\n\n\n\n\n\nTask 1: Create an editable project. Step 3: Once you sign in, the message changes, and you are invited to “MAKE A COPY” of the current project. Make a copy, to proceed.\n\n\n\n\n\nTask 1: Create an editable project. Step 4: Notice that, once you made a copy of the project, the crossed out “pen” symbol will change to a “normal pen”, and you will be able to edit and save the project."
  },
  {
    "objectID": "microreact/microreact.html#task-2-present-whole-genome-sequencing-quality-control-wgs-qc-statistics-in-a-chart.",
    "href": "microreact/microreact.html#task-2-present-whole-genome-sequencing-quality-control-wgs-qc-statistics-in-a-chart.",
    "title": "Microreact tutorial",
    "section": "Task 2: Present whole genome sequencing quality control (WGS QC) statistics in a chart.",
    "text": "Task 2: Present whole genome sequencing quality control (WGS QC) statistics in a chart.\n\n\n\nTask 2: Present WGS QC statistics in a chart. Step 1: Select the “Kpn Colombia” view. Click on the “Pen” symbol on the top right menu. Click on the “Create New Chart”\n\n\n\n\n\nTask 2: Present WGS QC statistics in a chart. Step 2: Drag the new chart to overlap with the tree.\n\n\n\n\n\nTask 2: Present WGS QC statistics in a chart. Step 3: An empty panel for the new chart will be shown on top of the tree panel.\n\n\n\n\n\nTask 2: Present WGS QC statistics in a chart. Step 4: In the Chart Type dropdown list select “Bar Chart”.\n\n\n\n\n\nTask2: Present WGS QC statistics in a chart. Step 5: A new window appears. In the X Axis Column, select “WGS_QC_no_contigs” and for “Maximum number of bins” select 10.\n\n\n\n\n\nTask 2: Present WGS QC statistics in a chart. Step 6: The bar chart will look like above. Observe that most genomes have less the 100 contigs."
  },
  {
    "objectID": "microreact/microreact.html#task-3-what-are-the-dominating-sequence-types-sts-in-colombia",
    "href": "microreact/microreact.html#task-3-what-are-the-dominating-sequence-types-sts-in-colombia",
    "title": "Microreact tutorial",
    "section": "Task 3: What are the dominating sequence types (STs) in Colombia?",
    "text": "Task 3: What are the dominating sequence types (STs) in Colombia?\n\n\n\nTask 3: What are the dominating STs in Colombia? Now that you’ve created one chart, you can create another one! Step 1: Go to the “Pen: symbol on the right hand side and click on the”Create New Chart”.\n\n\n\n\n\nTask 3: What are the dominating STs in Colombia? Step 2: The new chart can stay right on top of the previously created one.\n\n\n\n\n\nTask 3: What are the dominating STs in Colombia? Step 3: Notice a white canvas on top of the previously generated chart.\n\n\n\n\n\nTask 3: What are the dominating STs in Colombia? Step 4: Once again, from the Chart Type dropdown menu, select “Bar Chart”, and when the new view shows up on the “X Axis Column”, select ST.\n\n\n\n\n\nTask 3: What are the dominating STs in Colombia? Step 5: A new chart will appear. The labels on the x-axis appear squished and they are hard to read. Drag the panel divider on the left hand side of the chart, to increase the width of the panel.\n\n\n\n\n\nTask 3: What are the dominant STs in Colombia? Step 6: The information on the x-axis should be readable now. The 3 most abundant STs are ST11, ST258 and ST512.\n\n\n\n\n\nTask 3: What are the dominant STs in Colombia? Step 7: Click the “Views” panel on the left hand side, hover over “Kpn Colombia”, click on the three dots on the corner of the view and hit “Update View”\n\n\n\n\n\nTask 3: What are the dominant STs in Colombia? Step 8: Go to the Save icon on the right corner, press the icon and choose “Update This Project”"
  },
  {
    "objectID": "microreact/microreact.html#task-4-plot-metadata-blocks-for-the-carbapenamase-genes-ctx-m-15-ndm-1-kpc-and-oxa.-what-are-the-prevalent-amr-mechanisms-detected",
    "href": "microreact/microreact.html#task-4-plot-metadata-blocks-for-the-carbapenamase-genes-ctx-m-15-ndm-1-kpc-and-oxa.-what-are-the-prevalent-amr-mechanisms-detected",
    "title": "Microreact tutorial",
    "section": "Task 4: Plot metadata blocks for the carbapenamase genes CTX-M-15, NDM-1, KPC and OXA. What are the prevalent AMR mechanisms detected ?",
    "text": "Task 4: Plot metadata blocks for the carbapenamase genes CTX-M-15, NDM-1, KPC and OXA. What are the prevalent AMR mechanisms detected ?\n\n\n\nTask 4: Plot metadata blocks for CTX-M-15, NDM-1, KPC and OXA genes. What are the prevalent AMR mechanisms detected ? Step 1: Press the icon on the top right of the tree panel.\n\n\n\n\n\nTask 4: Plot metadata blocks for CTX-M-15, NDM-1, KPC and OXA genes. What are the prevalent AMR mechanisms detected ? Step 2: In the Metadata blocks dropdown list, tick all boxes containing KPC, NDM, VIM, OXA and CTX-M-15 genes.\n\n\n\n\n\nTask 4: Plot metadata blocks for CTX-M-15, NDM-1, KPC and OXA genes. What are the prevalent AMR mechanisms detected ? Step 3: The tree panel will show metadata columns. Yellow indicates presence of a certain gene and green indicates absence. In the panel shown here, it appears that the most common genes present are KPC-2, KPC-3, NDM-1 and CTX-M-15."
  },
  {
    "objectID": "microreact/microreact.html#task-5-which-sts-are-associated-with-the-presence-of-carbapenamase-genes",
    "href": "microreact/microreact.html#task-5-which-sts-are-associated-with-the-presence-of-carbapenamase-genes",
    "title": "Microreact tutorial",
    "section": "Task 5: Which STs are associated with the presence of carbapenamase genes?",
    "text": "Task 5: Which STs are associated with the presence of carbapenamase genes?\n\n\n\nTask 5: Which STs are associated with the presence of carbapenamase genes? Step 1: Go to the “Metadata blocks” and check the ST box.\n\n\n\n\n\nTask 5: Which STs are associated with the presence of carbapenamase genes? Step 2: Observe the new metadata column next to the tree, with the header “ST”.\n\n\n\n\n\nTask 5: Which STs are associated with the presence of carbapenamase genes? In the tree with added metadata blocks, we can observe a large brown block of isolates belonging to ST258. You will need to check the Legend on the very right of Microreact.\n\n\n\n\n\nTask 5: Which STs are associated with the presence of carbapenamase genes? On a close look, we can observe that ST258 is associated with the presence of the carbapenamase gene KPC-3."
  },
  {
    "objectID": "module2/module2.html",
    "href": "module2/module2.html",
    "title": "Module 2",
    "section": "",
    "text": "Follow the steps in Module 1 to connect to your remote virtual machine.\nThe next exercise is broadly based on the study https://journals.asm.org/doi/full/10.1128/msphere.00185-23 by Abrudan and Shamanna, 2023\n\n\n\nThe European Nucleotide Archive (ENA) provides a comprehensive record of the world’s nucleotide sequencing information, covering raw sequencing data, sequence assembly information and functional annotation.\nAccess to ENA data is provided through the browser, through search tools, through large scale file download and through the API."
  },
  {
    "objectID": "module2/module2.html#reads-qc",
    "href": "module2/module2.html#reads-qc",
    "title": "Module 2",
    "section": "Reads QC",
    "text": "Reads QC\nIn this part of the exercise, we will use a programme called FastQC.\nFastQC aims to provide a simple way to do some quality control checks on raw sequence data coming from high throughput sequencing pipelines. It provides a modular set of analyses which you can use to give a quick impression of whether your data has any problems of which you should be aware before doing any further analysis.\nThe main functions of FastQC are\n\nImport of data from BAM, SAM or FastQ files (any variant)\nProviding a quick overview to tell you in which areas there may be problems\nSummary graphs and tables to quickly assess your data\nExport of results to an HTML based permanent report\n\n\nRun FastQC programatically\nTo run non-interactively you simply have to specify a list of files to process on the command line. \nfastqc somefile.txt someotherfile.txt\nfastqc /home/ubuntu/data/*/*/*\n\n\nQC your fastq reads through the visual interface\nNavigate to /home/ubuntu/Software/FastQC and double click on the FastQC icon.\nIn the visual interface, open all files produced by FastQC and assess the results, eg ERR4635696_1_fastqc.html\nVisualize and interpret the FastQC results. Compare the QC results for Nanopore and Illumina sequence reads\nOptional: Unzip the files /home/ubuntu/Data/*/*/*_*_fastqc.zip and produce a script that extracts the information on reads lengths, GC contents etc; plot the results from all samples."
  },
  {
    "objectID": "module2/module2.html#speciation",
    "href": "module2/module2.html#speciation",
    "title": "Module 2",
    "section": "Speciation",
    "text": "Speciation\nBactinspector is a package to a) determine the most probable species based on sequence in fasta/fastq files using refseq and Mash (https://mash.readthedocs.io/en/latest/index.html) and b) determine the closest reference in refseq to a set of fasta/fastq files.\n\nGo to sample files /home/ubuntu/Data/ and run Bactinspector using the following command\n\nbactinspector closest_match -fq \"*_2.fastq.gz\"\n\nCheck the output *.tsv file\n\ntail -n +2 *.tsv| column -t | less -S\ncat *.tsv | tr \"\\t\" \"~\" | cut -d\"~\" -f2\nEg of a result:\nASM289538v1\nGCF_002895385\n\n\nHow do you interpret the results? Look up your results in ENA."
  },
  {
    "objectID": "module2/module2.html#genome-assembly",
    "href": "module2/module2.html#genome-assembly",
    "title": "Module 2",
    "section": "Genome assembly",
    "text": "Genome assembly\nThe Velvet assembler\nVelvet is an algorithm package that has been designed to deal with de novo genome assembly and short read sequencing alignments. This is achieved through the manipulation of de Bruijn graphs for genomic sequence assembly via the removal of errors and the simplification of repeated regions.\n\nRun Velvet\n\nVisualise the assembles using ACT and Artemis\nACT is a Java application for displaying pairwise comparisons between two or more DNA sequences.\nACT can be used to identify and analyse regions of similarity and difference between genomes and to explore conservation of synteny, in the context of the entire sequences and their annotation. It can read complete EMBL, GENBANK and GFF entries or sequences in FASTA or raw format.\nTip: ACT and Artemis are installed here: /usr/share/miniconda/pkgs/artemis-18.2.0-hdfd78af_0/share/artemis-18.2.0-0"
  },
  {
    "objectID": "module2/module2.html#assembly-qc-with-quast",
    "href": "module2/module2.html#assembly-qc-with-quast",
    "title": "Module 2",
    "section": "Assembly QC with Quast",
    "text": "Assembly QC with Quast\nQUAST stands for QUality ASsessment Tool. It evaluates genome/metagenome assemblies by computing various metrics. The current QUAST toolkit includes the general QUAST tool for genome assemblies, MetaQUAST, the extension for metagenomic datasets, QUAST-LG, the extension for large genomes (e.g., mammalians), and Icarus, the interactive visualizer for these tools.\nThe QUAST package works both with and without reference genomes. However, it is much more informative if at least a close reference genome is provided along with the assemblies. The tool accepts multiple assemblies, thus is suitable for comparison."
  },
  {
    "objectID": "module3/module3.html",
    "href": "module3/module3.html",
    "title": "Module 3",
    "section": "",
    "text": "Bacterial genome assembly data analysis\n\n\nTools to be used in Module 3\nARIBA\nARIBA is a tool that identifies antibiotic resistance genes by running local assemblies. It can also be used for MLST calling.\nThe input is a FASTA file of reference sequences (can be a mix of genes and noncoding sequences) and paired sequencing reads. ARIBA reports which of the reference sequences were found, plus detailed information on the quality of the assemblies and any variants between the sequencing reads and the reference sequences.\nFind out more at https://github.com/sanger-pathogens/ariba/wiki\n\nMulti Locus Sequence Typing (MLST)\n\nwhat is MLST, role and applications\n\nhttps://github.com/sanger-pathogens/ariba/wiki/MLST-calling-with-ARIBA\n\n\nAMR determinants\n\nIn your virtual machine, navigate to the folder /home/ubuntu/Data/all_fastas, where you will find all the assemblies for this study.\nRun ARIBA on the samples using the Resfinder database\n\nEg:\nariba run ARIBA_dbs/out.resfinder.prepareref all_fastqs/ERR017200_1.fastq.gz all_fastqs/ERR017200_2.fastq.gz ARIBA_output/ERR017200.run\n\nWrite a bash script to run ARIBA on multiple samples at once\nAggregate the ARIBA results\nVisualise the results.\nRun ARIBA on the samples using the CARD database\nCompare Resfinder and CARD results."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "This page is a repository for training resources designed and developed for the short course on Bacterial Genomics Bioinformatics, Babes-Bolyai University, Cluj-Napoca, Romania, November 2024, by Monica Abrudan.\nThe materials provided in this repository are FREE to use. This work is licensed under a Creative Commons Attribution 4.0 International License. Reuse is encouraged with acknowledgement.\nFind out more about the author here"
  },
  {
    "objectID": "microreact/microreact_doc.html",
    "href": "microreact/microreact_doc.html",
    "title": "Microreact documentation",
    "section": "",
    "text": "https://docs.microreact.org/"
  },
  {
    "objectID": "data-flo/data-flo_doc.html",
    "href": "data-flo/data-flo_doc.html",
    "title": "Data-flo documentation",
    "section": "",
    "text": "https://docs.data-flo.io/introduction/readme"
  },
  {
    "objectID": "module1/module1.html",
    "href": "module1/module1.html",
    "title": "Module 1",
    "section": "",
    "text": "Module 1: Set up your bioinformatics working environment\n\n\nPart 1: Connect to your Amazon EC2 instance via ssh\nBefore you start, make sure you received the IPv4 address of the virtual machine and your private key to connect to the machine from your course coordinator.\n\nUsing a Mac\nOpen your Terminal application on your local machine.\nThen type\nchmod 400 /local/path/to/student.pem\nssh -i /local/path/to/key.pem  ubuntu@xxx.xxx.xxx.xxx\nReplace the “xxx.xxx.xxx.xxx” with the Public IPv4 of your Amazon instance and the /local/path/to/student.pem with the local path to your student.pem file that was communicated to you previously.\nFor more information on how to connect to your virtual machine, access https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/connect-linux-inst-ssh.html .\n\n\nUsing a Windows machine\nSee https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/connect-linux-inst-from-windows.html\n\n\nHow to connect to your Amazon EC2 instance via your browser (during the course)\nType the Public IPv4 in your browser address bar, eg: https://xxx.xxx.xxx.xxx/\nType in the username ubuntu, and the password provided to you by the course instructor.\nOnce you log in, you should see the welcome screen.\nPlease reject any invitation to update the system.\n\n\nHow to modify your $PATH variable\nOnce you are connected to your Amazon EC2 Ubuntu instance, try to view and edit your configuration files. \nCheck the configuration files:\nls -a ~/.\nEdit the .profile file and add the paths in the PATH variable\nEg:\nvi ~/.profile\nPATH=\"/home/ubuntu/Software/mash-Linux64-v2.3:$PATH\"\n\n\n\nPart 2: Configure your Amazon EC2 Ubuntu instance\nYour Amazon EC2 Ubuntu instance should be ready to go right away. However, in order to go through the next modules of this course, you will need to install the list of tools below.\nFirst, familiarise yourselves with the tools. Understand what is their role in an NGS pipeline, what is the required input and the expected output. Who developed them and when? Do they have dependencies?\nFor each tool that you attempt to install, write down the steps you took to achieve that in the Shared student observations file, which you have received from your course coordinator.\n\nFastQC\nhttps://www.bioinformatics.babraham.ac.uk/projects/fastqc/\n\n\nBactinspector\nhttps://gitlab.com/antunderwood/bactinspector\n\n\nVelvet assembler\nhttps://github.com/dzerbino/velvet\n\n\n\nACT and Artemis\nhttps://www.sanger.ac.uk/tool/artemis-comparison-tool-act/\n\n\n\nUnicycler \nhttps://github.com/rrwick/Unicycler?tab=readme-ov-file#build-and-run-without-installation\n\n\n\nSPADES\nhttps://github.com/ablab/spades\n\n\n\nQuast\nhttps://github.com/ablab/quast\n\n\n\nbrew\nhttps://docs.brew.sh/Homebrew-on-Linux\n\n\n\nmakeblastdb and tblastn\nhttps://www.ncbi.nlm.nih.gov/books/NBK569861/\nprokka\nhttps://github.com/tseemann/prokka\n\n\n\nresfinder\nhttps://github.com/cadms/resfinder\n\nARIBA\nhttps://sanger-pathogens.github.io/ariba/ \nConfigure the MLST calling, Resfinder and CARD databases.\nariba pubmlstget \"Staphylococcus aureus\" get_mlst\nariba getref resfinder out.resfinder\nariba prepareref -f out.resfinder.fa -m out.resfinder.tsv out.resfinder.prepareref\nariba getref card out.card\nariba prepareref -f out.card.fa -m out.card.tsv out.card.prepareref\nHow to run ARIBA\nariba run out.ncbi.prepareref reads1.fastq reads2.fastq out.run"
  }
]